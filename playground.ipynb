{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./src/metadata.json', 'r') as f:\n",
    "    jtxt = f.read()\n",
    "\n",
    "j = json.loads(jtxt)\n",
    "def dig_dict(dictionary, pretab=0, indent=0):\n",
    "    config_string = ''\n",
    "    for key, val in dictionary.items():\n",
    "        config_string += '\\t'*(pretab + indent) + str(key) + '\\n'\n",
    "        print(key)\n",
    "        print('\\n\\n')\n",
    "        if isinstance(val, dict):\n",
    "            dig_dict(val, indent+1)\n",
    "        else:\n",
    "            config_string += '\\t'*(pretab + indent+1) + str(val) + '\\n'\n",
    "    return config_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant do in_streams\n",
      "Cant do streams\n"
     ]
    }
   ],
   "source": [
    "j.keys()\n",
    "type_dict = {}\n",
    "tag_dict = {}\n",
    "param_dict = {}\n",
    "optional_dict = {}\n",
    "\n",
    "j['schema'] = {k: v for k,v in j['schema'].items() if 'region' not in k.lower()}\n",
    "j['schema'] = {k: v for k,v in j['schema'].items() if 'inst' not in k.lower()}\n",
    "for arche, xml in j['schema'].items():\n",
    "    #print(xml)\n",
    "    schema_dict = xmltodict.parse(xml)\n",
    "    type_dict[arche] = {}\n",
    "    tag_dict[arche] = {}\n",
    "    optional_dict[arche] = []\n",
    "    param_dict[arche] = {'oneormore': [],\n",
    "                         'one': []}\n",
    "    if 'interleave' not in schema_dict.keys():\n",
    "        continue\n",
    "    for op_el in schema_dict['interleave']:\n",
    "        if op_el == 'element':\n",
    "            optional = False\n",
    "            if isinstance(schema_dict['interleave'][op_el], list):\n",
    "                for param in schema_dict['interleave'][op_el]:\n",
    "                    name = param['@name']\n",
    "                    if 'interleave' in param:\n",
    "                        print('%s Cant do man' %param)\n",
    "                        continue\n",
    "                    if 'data' in param:\n",
    "                        param_dict[arche]['one'].append(name)\n",
    "                        type_dict[arche][name] = param['data']['@type']\n",
    "                        continue\n",
    "                    if 'oneOrMore' in param:\n",
    "                        param_dict[arche]['oneormore'].append(name)\n",
    "                        tag_dict[arche][name] = param['oneOrMore']['element']['@name']\n",
    "                        if 'interleave' in param['oneOrMore']['element'].keys():\n",
    "                            print('Cant do %s' %name)\n",
    "                            continue\n",
    "                        type_dict[arche][name] = param['oneOrMore']['element']['data']['@type']\n",
    "            else:\n",
    "                param = schema_dict['interleave'][op_el]\n",
    "                name = param['@name']\n",
    "                if 'interleave' in param:\n",
    "                        print('%s Cant do man' %param)\n",
    "                        continue\n",
    "                if 'data' in param:\n",
    "                    param_dict[arche]['one'].append(name)\n",
    "                    type_dict[arche][name] = param['data']['@type']\n",
    "                    continue\n",
    "                if 'oneOrMore' in param:\n",
    "                    param_dict[arche]['oneormore'].append(name)\n",
    "                    tag_dict[arche][name] = param['oneOrMore']['element']['@name']\n",
    "                    if 'interleave' in param['oneOrMore']['element'].keys():\n",
    "                        print('Cant do %s' %param)\n",
    "                        continue\n",
    "                    type_dict[arche][name] = param['oneOrMore']['element']['data']['@type']\n",
    "        else:\n",
    "            optional = True\n",
    "            if isinstance(schema_dict['interleave'][op_el], list):\n",
    "                for param in schema_dict['interleave'][op_el]:\n",
    "                    param = param['element']\n",
    "                    name = param['@name']\n",
    "                    optional_dict[arche].append(name)\n",
    "                    if 'interleave' in param:\n",
    "                        print('%s Cant do man' %param)\n",
    "                        continue\n",
    "                    if 'data' in param:\n",
    "                        param_dict[arche]['one'].append(name)\n",
    "                        type_dict[arche][name] = param['data']['@type']\n",
    "                        continue\n",
    "                    if 'oneOrMore' in param:\n",
    "                        param_dict[arche]['oneormore'].append(name)\n",
    "                        tag_dict[arche][name] = param['oneOrMore']['element']['@name']\n",
    "                        type_dict[arche][name] = param['oneOrMore']['element']['data']['@type']        \n",
    "            else:\n",
    "                param = schema_dict['interleave'][op_el]['element']\n",
    "                name = param['@name']\n",
    "                optional_dict[arche].append(param['@name'])\n",
    "                if 'interleave' in param:\n",
    "                        print('%s Cant do man' %param)\n",
    "                        continue\n",
    "                if 'data' in param:\n",
    "                    param_dict[arche]['one'].append(name)\n",
    "                    type_dict[arche][name] = param['data']['@type']\n",
    "                    continue\n",
    "                if 'oneOrMore' in param:\n",
    "                    param_dict[arche]['oneormore'].append(name)\n",
    "                    tag_dict[arche][name] = param['oneOrMore']['element']['@name']\n",
    "                    type_dict[arche][name] = param['oneOrMore']['element']['data']['@type']   \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fuel_incommods': 'string', 'fuel_inrecipes': 'string', 'fuel_outcommods': 'string', 'fuel_outrecipes': 'string', 'assem_size': 'double', 'n_assem_batch': 'int', 'fuel_prefs': 'double', 'recipe_change_times': 'int', 'recipe_change_commods': 'string', 'recipe_change_in': 'string', 'recipe_change_out': 'string', 'n_assem_core': 'int', 'n_assem_fresh': 'int', 'n_assem_spent': 'int', 'cycle_time': 'int', 'refuel_time': 'int', 'cycle_step': 'int', 'power_cap': 'double', 'power_name': 'string', 'side_products': 'string', 'side_product_quantity': 'double', 'pref_change_times': 'int', 'pref_change_commods': 'string', 'pref_change_values': 'double', 'latitude': 'double', 'longitude': 'double'}\n",
      "\n",
      "\n",
      "\n",
      "{'fuel_incommods': 'val', 'fuel_inrecipes': 'val', 'fuel_outcommods': 'val', 'fuel_outrecipes': 'val', 'fuel_prefs': 'val', 'recipe_change_times': 'val', 'recipe_change_commods': 'val', 'recipe_change_in': 'val', 'recipe_change_out': 'val', 'side_products': 'val', 'side_product_quantity': 'val', 'pref_change_times': 'val', 'pref_change_commods': 'val', 'pref_change_values': 'val'}\n",
      "\n",
      "\n",
      "\n",
      "{'oneormore': ['fuel_incommods', 'fuel_inrecipes', 'fuel_outcommods', 'fuel_outrecipes', 'fuel_prefs', 'recipe_change_times', 'recipe_change_commods', 'recipe_change_in', 'recipe_change_out', 'side_products', 'side_product_quantity', 'pref_change_times', 'pref_change_commods', 'pref_change_values'], 'one': ['assem_size', 'n_assem_batch', 'n_assem_core', 'n_assem_fresh', 'n_assem_spent', 'cycle_time', 'refuel_time', 'cycle_step', 'power_cap', 'power_name', 'latitude', 'longitude']}\n",
      "\n",
      "\n",
      "\n",
      "['fuel_prefs', 'recipe_change_times', 'recipe_change_commods', 'recipe_change_in', 'recipe_change_out', 'n_assem_core', 'n_assem_fresh', 'n_assem_spent', 'cycle_time', 'refuel_time', 'cycle_step', 'power_cap', 'power_name', 'side_products', 'side_product_quantity', 'pref_change_times', 'pref_change_commods', 'pref_change_values', 'latitude', 'longitude']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type_dict[':cycamore:Reactor'])\n",
    "print('\\n\\n')\n",
    "print(tag_dict[':cycamore:Reactor'])\n",
    "print('\\n\\n')\n",
    "print(param_dict[':cycamore:Reactor'])\n",
    "print('\\n\\n')\n",
    "print(optional_dict[':cycamore:Reactor'])\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":agents:KFacility\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-c01f41ec968e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mel_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'optional'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'schema'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interleave'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mel_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mparam_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'@name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'oneOrMore'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "for i in j['schema']:\n",
    "    tag_dict = {i: {}}\n",
    "    fac_dict = xmltodict.parse(j['schema'][i])['interleave']\n",
    "    for el_op in fac_dict:\n",
    "        if el_op == 'element':\n",
    "            optional = False\n",
    "        elif el_op == 'optional':\n",
    "            optional = True\n",
    "        for param in fac_dict[el_op]:\n",
    "            param_dict = {}\n",
    "            param_name = param['@name']\n",
    "            if 'interleave' in param.keys():\n",
    "                param_dict = interleave_digger(param, param_dict)\n",
    "            if 'oneOrMore' in param.keys():\n",
    "                param_dict = oneOrMore_digger(param, param_dict)\n",
    "            if 'data' in param.keys():\n",
    "                param_dict = data_digger(param, param_dict)\n",
    "                \n",
    "def interleave_digger(d, param_dict):\n",
    "    for i in d['interleave']['element']:\n",
    "        new_dict = d['element']\n",
    "        name = new_dict['@name']\n",
    "        if 'interleave' in new_dict.keys():\n",
    "            interleave_digger(new_dict, param_dict)\n",
    "        elif 'oneOrMore' in new_dict.keys():\n",
    "            oneOrMore_digger(new_dict, param_dict)\n",
    "        elif 'data' in new_dict.keys():\n",
    "            data_digger(new_dict, param_dict)\n",
    "    \n",
    "def oneOrMore_digger(d):\n",
    "    \n",
    "    if 'interleave' in new_dict.keys():\n",
    "        interleave_digger(new_dict, param_dict)\n",
    "    elif 'oneOrMore' in new_dict.keys():\n",
    "        oneOrMore_digger(new_dict, param_dict)\n",
    "    elif 'data' in new_dict.keys():\n",
    "        data_digger(new_dict, param_dict)\n",
    "\n",
    "def data_digger(d):\n",
    "    \n",
    "    \n",
    "        \n",
    "\"\"\"        \n",
    "        for param in j['schema'][i]['interleave'][el_op]:\n",
    "            param_name = param['@name'] \n",
    "            if 'oneOrMore' in param.keys():\n",
    "                oneormore = True\n",
    "                tag = param_name['oneOrMore']['element']['@name']\n",
    "                # if 'interleave' in param_name['oneOrMore']['element']\n",
    "                    \n",
    "            else:\n",
    "                oneormore = False\n",
    "\"\"\"         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feed (['cyclus::toolkit::ResBuf', 'cyclus::Material']):\n",
      "\n",
      "Default:\n",
      "\n",
      "\n",
      "feed_commod_prefs (['std::vector', 'double']):\n",
      "Feed commodity request preferences for each of the given feed commodities (same order). If unspecified, default is to use 1.0 for all preferences.\n",
      "Default:[]\n",
      "\n",
      "\n",
      "feed_commods (['std::vector', 'std::string']):\n",
      "Ordered list of commodities on which to request feed material to separate. Order only matters for matching up with feed commodity preferences if specified.\n",
      "Default:\n",
      "\n",
      "\n",
      "feed_recipe (std::string):\n",
      "Name for recipe to be used in feed requests. Empty string results in use of a dummy recipe.\n",
      "Default:\n",
      "\n",
      "\n",
      "feedbuf_size (double):\n",
      "Maximum amount of feed material to keep on hand.\n",
      "Default:\n",
      "\n",
      "\n",
      "latitude (double):\n",
      "Latitude of the agent's geographical position. The value should be expressed in degrees as a double.\n",
      "Default:0.0\n",
      "\n",
      "\n",
      "leftover (['cyclus::toolkit::ResBuf', 'cyclus::Material']):\n",
      "\n",
      "Default:\n",
      "\n",
      "\n",
      "leftover_commod (std::string):\n",
      "Commodity on which to trade the leftover separated material stream. This MUST NOT be the same as any commodity used to define the other separations streams.\n",
      "Default:default-waste-stream\n",
      "\n",
      "\n",
      "leftoverbuf_size (double):\n",
      "Maximum amount of leftover separated material (not included in any other stream) that can be stored. If full, the facility halts operation until space becomes available.\n",
      "Default:1e+299\n",
      "\n",
      "\n",
      "longitude (double):\n",
      "Longitude of the agent's geographical position. The value should be expressed in degrees as a double.\n",
      "Default:0.0\n",
      "\n",
      "\n",
      "WHY IS streams_ a string\n",
      "\n",
      "streams_ (['std::map', 'std::string', ['std::pair', 'double', ['std::map', 'int', 'double']]]):\n",
      "Output streams for separations. Each stream must have a unique name identifying the commodity on  which its material is traded, a max buffer capacity in kg (neg values indicate infinite size), and a set of component efficiencies. 'comp' is a component to be separated into the stream (e.g. U, Pu, etc.) and 'eff' is the mass fraction of the component that is separated from the feed into this output stream. If any stream buffer is full, the facility halts operation until space becomes available. The sum total of all component efficiencies across streams must be less than or equal to 1 (e.g. sum of U efficiencies for all streams must be <= 1).\n",
      "Default:\n",
      "\n",
      "\n",
      "throughput (double):\n",
      "Maximum quantity of feed material that can be processed per time step.\n",
      "Default:1e+299\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = j['annotations'][':cycamore:Separations']['doc']\n",
    "variables = j['annotations'][':cycamore:Separations']['vars']\n",
    "def parse_variable_dict(variable_dict):\n",
    "    for name, specs in variable_dict.items():\n",
    "        if isinstance(specs, str):\n",
    "            print('WHY IS %s a string\\n' %specs)\n",
    "            continue \n",
    "    \n",
    "        if 'doc' in specs.keys():\n",
    "            doc_ = specs['doc']\n",
    "        elif 'tooltip' in specs.keys():\n",
    "            doc_ = specs['tooltip']\n",
    "        else:\n",
    "            doc_ = ''\n",
    "        \n",
    "        if 'type' in specs.keys():\n",
    "            type_ = specs['type']\n",
    "        else:\n",
    "            type_ = ''\n",
    "            \n",
    "        if 'default' in specs.keys():\n",
    "            default_ = specs['default']\n",
    "        else:\n",
    "            default_ = ''\n",
    "        \n",
    "        print('%s (%s):\\n%s\\n%s' %(name, type_, doc_, 'Default:%s'%default_))\n",
    "        print('\\n')\n",
    "    \n",
    "parse_variable_dict(variables)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feed\n",
      "[-1, -1]\n",
      "feed_commod_prefs\n",
      "[-1, -1]\n",
      "feed_commods\n",
      "[-1, -1]\n",
      "feed_recipe\n",
      "[-1]\n",
      "feedbuf_size\n",
      "[-1]\n",
      "latitude\n",
      "[-1]\n",
      "leftover\n",
      "[-1, -1]\n",
      "leftover_commod\n",
      "[-1]\n",
      "leftoverbuf_size\n",
      "[-1]\n",
      "longitude\n",
      "[-1]\n",
      "streams\n",
      "streams_\n",
      "streams_\n",
      "[-1, -1, -1, -1, -1, -1, -1]\n",
      "throughput\n",
      "[-1]\n"
     ]
    }
   ],
   "source": [
    "for key, val in variables.items():\n",
    "    print(key)\n",
    "    try:\n",
    "        print(val['shape'])\n",
    "    except:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'enrichment'), ('config', OrderedDict([('Enrichment', OrderedDict([('feed_commod', 'natl_u'), ('feed_recipe', 'natl_u'), ('product_commod', 'uox'), ('tails_assay', '0.003'), ('tails_commod', 'waste'), ('swu_capacity', '1e100'), ('initial_feed', '1e100')]))]))])\n",
      "\n",
      "\n",
      "\n",
      "OrderedDict([('name', 'separations'), ('config', OrderedDict([('Separations', OrderedDict([('streams', OrderedDict([('item', OrderedDict([('commod', 'sep_stream'), ('info', OrderedDict([('buf_size', '1e100'), ('efficiencies', OrderedDict([('item', OrderedDict([('comp', 'Pu'), ('eff', '.99')]))]))]))]))])), ('leftover_commod', 'waste'), ('throughput', '30001'), ('feedbuf_size', '30001'), ('feed_commods', OrderedDict([('val', 'spent_uox')])), ('feed_commod_prefs', OrderedDict([('val', '2.0')]))]))]))])\n",
      "\n",
      "\n",
      "\n",
      "OrderedDict([('name', 'fuelfab'), ('config', OrderedDict([('FuelFab', OrderedDict([('fill_commods', OrderedDict([('val', 'depleted_u')])), ('fill_recipe', 'depleted_u'), ('fill_size', '30001'), ('fiss_commods', OrderedDict([('val', 'sep_stream')])), ('fiss_size', '15000'), ('spectrum', 'thermal'), ('outcommod', 'mox'), ('throughput', '30001')]))]))])\n",
      "\n",
      "\n",
      "\n",
      "OrderedDict([('name', 'reactor'), ('config', OrderedDict([('Reactor', OrderedDict([('fuel_inrecipes', OrderedDict([('val', ['fresh_uox', 'fresh_mox'])])), ('fuel_outrecipes', OrderedDict([('val', ['spent_uox', 'spent_mox'])])), ('fuel_incommods', OrderedDict([('val', ['uox', 'mox'])])), ('fuel_outcommods', OrderedDict([('val', ['spent_uox', 'waste'])])), ('fuel_prefs', OrderedDict([('val', ['1.0', '2.0'])])), ('cycle_time', '17'), ('refuel_time', '2'), ('assem_size', '30000'), ('n_assem_core', '3'), ('n_assem_batch', '1')]))]))])\n",
      "\n",
      "\n",
      "\n",
      "OrderedDict([('name', 'repo'), ('config', OrderedDict([('Sink', OrderedDict([('in_commods', OrderedDict([('val', 'waste')])), ('capacity', '1e100')]))]))])\n",
      "\n",
      "\n",
      "\n",
      "OrderedDict([('name', 'depleted_src'), ('config', OrderedDict([('Source', OrderedDict([('outcommod', 'depleted_u'), ('outrecipe', 'depleted_u')]))]))])\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proto_dict = {}\n",
    "with open('./output_c98/prototypes.xml', 'r') as f:\n",
    "    xml_list = xmltodict.parse(f.read())['root']['facility']\n",
    "    for facility in xml_list:\n",
    "        print(facility)\n",
    "        print('\\n\\n')\n",
    "        facility_name = facility['name']\n",
    "        archetype = list(facility['config'].keys())[0]\n",
    "        # proto_dict[facility_name] = {'archetype': archetype,\n",
    "        #                              'config': facility['config'][archetype]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enrichment': {'archetype': 'Enrichment',\n",
       "  'config': OrderedDict([('feed_commod', 'natl_u'),\n",
       "               ('feed_recipe', 'natl_u'),\n",
       "               ('product_commod', 'uox'),\n",
       "               ('tails_assay', '0.003'),\n",
       "               ('tails_commod', 'waste'),\n",
       "               ('swu_capacity', '1e100'),\n",
       "               ('initial_feed', '1e100')])},\n",
       " 'separations': {'archetype': 'Separations',\n",
       "  'config': OrderedDict([('streams',\n",
       "                OrderedDict([('item',\n",
       "                              OrderedDict([('commod', 'sep_stream'),\n",
       "                                           ('info',\n",
       "                                            OrderedDict([('buf_size', '1e100'),\n",
       "                                                         ('efficiencies',\n",
       "                                                          OrderedDict([('item',\n",
       "                                                                        OrderedDict([('comp',\n",
       "                                                                                      'Pu'),\n",
       "                                                                                     ('eff',\n",
       "                                                                                      '.99')]))]))]))]))])),\n",
       "               ('leftover_commod', 'waste'),\n",
       "               ('throughput', '30001'),\n",
       "               ('feedbuf_size', '30001'),\n",
       "               ('feed_commods', OrderedDict([('val', 'spent_uox')])),\n",
       "               ('feed_commod_prefs', OrderedDict([('val', '2.0')]))])},\n",
       " 'fuelfab': {'archetype': 'FuelFab',\n",
       "  'config': OrderedDict([('fill_commods',\n",
       "                OrderedDict([('val', 'depleted_u')])),\n",
       "               ('fill_recipe', 'depleted_u'),\n",
       "               ('fill_size', '30001'),\n",
       "               ('fiss_commods', OrderedDict([('val', 'sep_stream')])),\n",
       "               ('fiss_size', '15000'),\n",
       "               ('spectrum', 'thermal'),\n",
       "               ('outcommod', 'mox'),\n",
       "               ('throughput', '30001')])},\n",
       " 'reactor': {'archetype': 'Reactor',\n",
       "  'config': OrderedDict([('fuel_inrecipes',\n",
       "                OrderedDict([('val', ['fresh_uox', 'fresh_mox'])])),\n",
       "               ('fuel_outrecipes',\n",
       "                OrderedDict([('val', ['spent_uox', 'spent_mox'])])),\n",
       "               ('fuel_incommods', OrderedDict([('val', ['uox', 'mox'])])),\n",
       "               ('fuel_outcommods',\n",
       "                OrderedDict([('val', ['spent_uox', 'waste'])])),\n",
       "               ('fuel_prefs', OrderedDict([('val', ['1.0', '2.0'])])),\n",
       "               ('cycle_time', '17'),\n",
       "               ('refuel_time', '2'),\n",
       "               ('assem_size', '30000'),\n",
       "               ('n_assem_core', '3'),\n",
       "               ('n_assem_batch', '1')])},\n",
       " 'repo': {'archetype': 'Sink',\n",
       "  'config': OrderedDict([('in_commods', OrderedDict([('val', 'waste')])),\n",
       "               ('capacity', '1e100')])},\n",
       " 'depleted_src': {'archetype': 'Source',\n",
       "  'config': OrderedDict([('outcommod', 'depleted_u'),\n",
       "               ('outrecipe', 'depleted_u')])}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "proto_dict = {'enrichment': {'archetype': 'Enrichment', 'config': OrderedDict([('feed_commod', 'natl_u'), ('feed_recipe', 'natl_u'), ('product_commod', 'uox'), ('tails_assay', '0.003'), ('tails_commod', 'waste'), ('swu_capacity', '1e100'), ('initial_feed', '1e100')])}, 'separations': {'archetype': 'Separations', 'config': OrderedDict([('streams', OrderedDict([('item', OrderedDict([('commod', 'sep_stream'), ('info', OrderedDict([('buf_size', '1e100'), ('efficiencies', OrderedDict([('item', OrderedDict([('comp', 'Pu'), ('eff', '.99')]))]))]))]))])), ('leftover_commod', 'waste'), ('throughput', '30001'), ('feedbuf_size', '30001'), ('feed_commods', OrderedDict([('val', 'spent_uox')])), ('feed_commod_prefs', OrderedDict([('val', '2.0')]))])}, 'fuelfab': {'archetype': 'FuelFab', 'config': OrderedDict([('fill_commods', OrderedDict([('val', 'depleted_u')])), ('fill_recipe', 'depleted_u'), ('fill_size', '30001'), ('fiss_commods', OrderedDict([('val', 'sep_stream')])), ('fiss_size', '15000'), ('spectrum', 'thermal'), ('outcommod', 'mox'), ('throughput', '30001')])}, 'reactor': {'archetype': 'Reactor', 'config': OrderedDict([('fuel_inrecipes', OrderedDict([('val', ['fresh_uox', 'fresh_mox'])])), ('fuel_outrecipes', OrderedDict([('val', ['spent_uox', 'spent_mox'])])), ('fuel_incommods', OrderedDict([('val', ['uox', 'mox'])])), ('fuel_outcommods', OrderedDict([('val', ['spent_uox', 'waste'])])), ('fuel_prefs', OrderedDict([('val', ['1.0', '2.0'])])), ('cycle_time', '17'), ('refuel_time', '2'), ('assem_size', '30000'), ('n_assem_core', '3'), ('n_assem_batch', '1')])}, 'repo': {'archetype': 'Sink', 'config': OrderedDict([('in_commods', OrderedDict([('val', 'waste')])), ('capacity', '1e100')])}, 'depleted_src': {'archetype': 'Source', 'config': OrderedDict([('outcommod', 'depleted_u'), ('outrecipe', 'depleted_u')])}}\n",
    "proto_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reactor': {'fuel_incommods': {'val': ['inc1', 'inc2']}, 'assem_size': '30'}}\n"
     ]
    }
   ],
   "source": [
    "new_dict = {'root': {'facility': []}}\n",
    "proto_dict = {'reac1': {'archetype': 'Reactor', 'config': {'Reactor': {'fuel_incommods': {'val': ['inc1', 'inc2']}, 'assem_size': '30'}}}}\n",
    "for name, config in proto_dict.items():\n",
    "    facility_dict = {}\n",
    "    facility_dict['name'] = name\n",
    "    print(config['config'])\n",
    "    facility_dict['config'] = {config['archetype']: config['config']}\n",
    "    new_dict['root']['facility'].append(facility_dict)\n",
    "\n",
    "f = open('./test.xml', 'w')\n",
    "f.write(xmltodict.unparse(new_dict, pretty=True))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'depleted_src',\n",
       " 'config': OrderedDict([('Source',\n",
       "               OrderedDict([('outcommod', 'depleted_u'),\n",
       "                            ('outrecipe', 'depleted_u')]))])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = OrderedDict([('name', 'depleted_src'), ('config', OrderedDict([('Source', OrderedDict([('outcommod', 'depleted_u'), ('outrecipe', 'depleted_u')]))]))])\n",
    "dict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('item',\n",
       "              [OrderedDict([('commod', 'mox_TRU'),\n",
       "                            ('info',\n",
       "                             OrderedDict([('buf_size', '1E100'),\n",
       "                                          ('efficiencies',\n",
       "                                           OrderedDict([('item',\n",
       "                                                         [OrderedDict([('comp',\n",
       "                                                                        'Np'),\n",
       "                                                                       ('eff',\n",
       "                                                                        '.998')]),\n",
       "                                                          OrderedDict([('comp',\n",
       "                                                                        'Am'),\n",
       "                                                                       ('eff',\n",
       "                                                                        '.998')]),\n",
       "                                                          OrderedDict([('comp',\n",
       "                                                                        'Cm'),\n",
       "                                                                       ('eff',\n",
       "                                                                        '.998')]),\n",
       "                                                          OrderedDict([('comp',\n",
       "                                                                        'Pu'),\n",
       "                                                                       ('eff',\n",
       "                                                                        '.998')])])]))]))]),\n",
       "               OrderedDict([('commod', 'mox_U'),\n",
       "                            ('info',\n",
       "                             OrderedDict([('buf_size', '1E100'),\n",
       "                                          ('efficiencies',\n",
       "                                           OrderedDict([('item',\n",
       "                                                         OrderedDict([('comp',\n",
       "                                                                       'U'),\n",
       "                                                                      ('eff',\n",
       "                                                                       '.998')]))]))]))])])])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =\"\"\"<facility>\n",
    "    <name>mox_reprocessing</name>\n",
    "    <config>\n",
    "      <Separations>\n",
    "         <feed_commods>   <val>cool_mox_waste</val>  </feed_commods>\n",
    "         <feed_commod_prefs> <val>2.0</val> </feed_commod_prefs>\n",
    "         <feedbuf_size>1E100</feedbuf_size>\n",
    "         <throughput>1E100</throughput>\n",
    "         <leftover_commod>mox_reprocess_waste</leftover_commod>\n",
    "         <leftoverbuf_size>1E100</leftoverbuf_size>\n",
    "         <streams>\n",
    "          <item>\n",
    "            <commod>mox_TRU</commod>\n",
    "            <info>\n",
    "              <buf_size>1E100</buf_size>\n",
    "              <efficiencies>\n",
    "                <item>\n",
    "                  <comp>Np</comp> <eff>.998</eff>\n",
    "                </item>\n",
    "                <item>\n",
    "                  <comp>Am</comp> <eff>.998</eff>\n",
    "                </item>\n",
    "                <item>\n",
    "                  <comp>Cm</comp> <eff>.998</eff>\n",
    "                </item>\n",
    "                <item>\n",
    "                  <comp>Pu</comp> <eff>.998</eff>\n",
    "                </item>\n",
    "              </efficiencies>\n",
    "            </info>\n",
    "          </item>\n",
    "          <item>\n",
    "            <commod>mox_U</commod>\n",
    "            <info>\n",
    "              <buf_size>1E100</buf_size>\n",
    "              <efficiencies>\n",
    "                <item>\n",
    "                  <comp>U</comp> <eff>.998</eff>\n",
    "                </item>\n",
    "              </efficiencies>\n",
    "            </info>\n",
    "          </item>\n",
    "        </streams>\n",
    "      </Separations>\n",
    "    </config>\n",
    "</facility>\"\"\"\n",
    "xmltodict.parse(x)['facility']['config']['Separations']['streams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
